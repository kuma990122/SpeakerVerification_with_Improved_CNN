{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.max_length = 0\n",
    "        self.feature_count = 0\n",
    "        label_map = {}  # 用于映射字符标签到整数标签的字典\n",
    "        label_index = 0\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('embedding_txt'):\n",
    "                self.feature_count += 1\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    for line in f:\n",
    "                        mfcc_features = [float(x) for x in line.split()]\n",
    "                        if len(mfcc_features) > self.max_length:\n",
    "                           self.max_length = len(mfcc_features)\n",
    "        dataset_size = self.feature_count\n",
    "        print(\"Feature amounts: \",self.feature_count)\n",
    "        print(\"Dataset size: \",dataset_size)\n",
    "                    \n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('embedding_txt'):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    for line in f:\n",
    "                        mfcc_features = [float(x) for x in line.split()]\n",
    "                        # 填充特征向量到相同长度\n",
    "                        if len(mfcc_features)< self.max_length:\n",
    "                            mfcc_features = self.paddingByMaxLength(mfcc_features)\n",
    "                        mfcc_features_tensor = torch.tensor(mfcc_features, dtype=torch.float32)\n",
    "                        self.data.append(mfcc_features_tensor)\n",
    "                        speaker_id = os.path.basename(file_path)[:3]\n",
    "                        if speaker_id not in label_map:\n",
    "                            label_map[speaker_id] = label_index\n",
    "                            label_index += 1\n",
    "                        self.labels.append(label_map[speaker_id])\n",
    "        print(\"Label size: \",len(self.labels))\n",
    "                        \n",
    "    def paddingByMaxLength(self, features):\n",
    "        if len(features) < self.max_length:\n",
    "            padded_features = features + [0.0] * (self.max_length - len(features))\n",
    "            return padded_features\n",
    "        return features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        features_tensor = self.data[idx]\n",
    "        label_tensor = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
    "        return {'features': features_tensor, 'label': label_tensor}\n",
    "\n",
    "\n",
    "dataset_size = 0       \n",
    "batch_size = 64\n",
    "train_path = '../../split_data/train'\n",
    "valid_path = '../../split_data/validation'\n",
    "test_path = '../../split_data/test'\n",
    "train_dataset = MyDataset(train_path)\n",
    "val_dataset = MyDataset(valid_path)\n",
    "test_dataset = MyDataset(test_path)\n",
    "def train_dataloader(train_dataset):\n",
    "        return DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def val_dataloader(val_dataset):\n",
    "        return DataLoader(dataset=val_dataset, batch_size=batch_size)\n",
    "\n",
    "def test_dataloader(test_dataset):\n",
    "        return DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#loading dataloader\n",
    "trainloader = train_dataloader(train_dataset)\n",
    "validationloader = val_dataloader(val_dataset)\n",
    "testloader = test_dataloader(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "class MyMelDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, folder_path,transform):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.feature_count = 0\n",
    "        label_map = {}  # 用于映射字符标签到整数标签的字典\n",
    "        label_index = 0\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('png'):\n",
    "                self.feature_count += 1\n",
    "                img_name = os.path.join(folder_path,file_name)\n",
    "                image = Image.open(img_name)\n",
    "                image_tensor = self.transform(image)\n",
    "                self.data.append(image_tensor)\n",
    "                speaker_id = os.path.basename(file_name)[:3]\n",
    "                if speaker_id not in label_map:\n",
    "                            label_map[speaker_id] = label_index\n",
    "                            label_index += 1\n",
    "                self.labels.append(label_map[speaker_id])\n",
    "        print(\"Feature amounts: \", self.feature_count)        \n",
    "        print(\"Label size: \",len(self.labels))\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        features_tensor = self.data[idx]\n",
    "        label_tensor = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
    "        return {'features': features_tensor, 'label': label_tensor}\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((277, 109)),  # 调整图像大小\n",
    "    transforms.ToTensor(),           # 转换为张量\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # 标准化\n",
    "])\n",
    "\n",
    "train_path_Mel = '../../split_data/train_Mel'\n",
    "valid_path_Mel = '../../split_data/validation_Mel'\n",
    "test_path_Mel = '../../split_data/test_Mel'\n",
    "\n",
    "train_dataset_Mel= MyMelDataset(train_path_Mel,transform=transform)\n",
    "val_dataset_Mel = MyMelDataset(valid_path_Mel,transform = transform)\n",
    "test_dataset_Mel = MyMelDataset(test_path_Mel, transform= transform)\n",
    "\n",
    "trainloader_Mel = train_dataloader(train_dataset_Mel)\n",
    "validationloader_Mel = val_dataloader(val_dataset_Mel)\n",
    "testloader_Mel = test_dataloader(test_dataset_Mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for data in trainloader_Mel:\n",
    "    print(\"Features shape:\", data['features'].shape)\n",
    "    print(\"Labels shape:\", data['label'].shape)\n",
    "    print(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resNetModel = models.resnet50(pretrained = True)\n",
    "# 获取第一个卷积层的权重\n",
    "conv1_weight = resNetModel.conv1.weight\n",
    "\n",
    "# 将通道数修改为1\n",
    "modified_conv1_weight = conv1_weight[:, :4, :, :]\n",
    "\n",
    "# 修改模型的第一个卷积层的权重\n",
    "resNetModel.conv1 = torch.nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#resNetModel.conv1.weight.data = modified_conv1_weight\n",
    "\n",
    "# 检查修改后的模型结构\n",
    "print(resNetModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resNetModel.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resNetModel.parameters(), lr=0.001)\n",
    "\n",
    "log_dir = \"./logs/resNet50\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "best_accuracy = 0.0  # 初始化最佳准确率为0\n",
    "best_model_path = \"./best_restNetmodel.pth\"  # 模型保存路径\n",
    "\n",
    "train_losses = []\n",
    "validations = []\n",
    "print(\"Number of mini-batches in one epoch:\", len(trainloader_Mel))\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0  \n",
    "    for i, data in enumerate(trainloader_Mel, 0):\n",
    "        inputs_origin = data['features']\n",
    "        inputs_new = inputs_origin.squeeze(1).squeeze(2)\n",
    "        inputs, labels = inputs_new.to(device), data['label'].to(device)  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resNetModel(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % len(trainloader_Mel) == len(trainloader_Mel) - 1:\n",
    "            average_loss = running_loss / 100\n",
    "            print(f\"Epoch {epoch+1}, Batch {i+1}, Loss: {average_loss:.6f}\")\n",
    "\n",
    "            train_losses.append(average_loss)\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # 在每个epoch结束后执行验证集评估\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validationloader_Mel:\n",
    "            inputs_origin = data['features']\n",
    "            inputs_new = inputs_origin.squeeze(1).squeeze(2)\n",
    "            inputs, labels = inputs_new.to(device), data['label'].to(device)\n",
    "            outputs = resNetModel(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * (correct / total)\n",
    "    validations.append(accuracy)\n",
    "    print(f\"Epoch {epoch+1}, Validation Accuracy: {accuracy:.6f}%\")\n",
    "\n",
    "    # 如果当前模型在验证集上表现优于之前的最佳表现，则保存当前模型参数\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(resNetModel.state_dict(), best_model_path)\n",
    "        print(\"Best model saved with validation accuracy:\", best_accuracy)\n",
    "print(\"After training, the best model saved with validation accuracy:\", best_accuracy)    \n",
    "plt.plot(validations, label = \"Validation Accuracy\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "print(\"resNetModel Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileNetModel = models.mobilenet_v2(pretrained = True)\n",
    "# 修改第一个卷积层的输入通道数\n",
    "mobileNetModel.features[0][0] = nn.Conv2d(4, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "\n",
    "# 打印修改后的模型结构\n",
    "print(mobileNetModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "mobileNetModel.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mobileNetModel.parameters(), lr=0.001)\n",
    "\n",
    "log_dir = \"./logs/mobileNet_v2\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "best_accuracy = 0.0  # 初始化最佳准确率为0\n",
    "best_model_path = \"./best_mobilemodel.pth\"  # 模型保存路径\n",
    "\n",
    "validations = []\n",
    "\n",
    "print(\"Number of mini-batches in one epoch:\", len(trainloader_Mel))\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0  \n",
    "    for i, data in enumerate(trainloader_Mel, 0):\n",
    "        inputs_origin = data['features']\n",
    "        inputs_new = inputs_origin.squeeze(1).squeeze(2)\n",
    "        inputs, labels = inputs_new.to(device), data['label'].to(device)  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = mobileNetModel(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % len(trainloader_Mel) == len(trainloader_Mel) - 1:\n",
    "            average_loss = running_loss / 100\n",
    "            print(f\"Epoch {epoch+1}, Batch {i+1}, Loss: {average_loss:.6f}\")\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # 在每个epoch结束后执行验证集评估\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validationloader_Mel:\n",
    "            inputs_origin = data['features']\n",
    "            inputs_new = inputs_origin.squeeze(1).squeeze(2)\n",
    "            inputs, labels = inputs_new.to(device), data['label'].to(device)\n",
    "            outputs = mobileNetModel(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * (correct / total)\n",
    "    validations.append(accuracy)\n",
    "    print(f\"Epoch {epoch+1}, Validation Accuracy: {accuracy:.6f}%\")\n",
    "\n",
    "    # 如果当前模型在验证集上表现优于之前的最佳表现，则保存当前模型参数\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(mobileNetModel.state_dict(), best_model_path)\n",
    "        print(\"Best model saved with validation accuracy:\", best_accuracy)\n",
    "\n",
    "print(\"After training, the best model saved with validation accuracy:\", best_accuracy)   \n",
    "plt.plot(validations, label = \"Validation Accuracy\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "print(\"mobileNetModel Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNetModel = models.densenet201(pretrained = True)\n",
    "# 修改第一个卷积层的输入通道数\n",
    "denseNetModel.features.conv0 = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "# 打印修改后的模型结构\n",
    "print(denseNetModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "denseNetModel.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(denseNetModel.parameters(), lr=0.001)\n",
    "\n",
    "log_dir = \"./logs/resNet50\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "best_accuracy = 0.0  # 初始化最佳准确率为0\n",
    "best_model_path = \"./best_denseNetmodel.pth\"  # 模型保存路径\n",
    "validations = []\n",
    "\n",
    "print(\"Number of mini-batches in one epoch:\", len(trainloader_Mel))\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0  \n",
    "    for i, data in enumerate(trainloader_Mel, 0):\n",
    "        inputs_origin = data['features']\n",
    "        inputs_new = inputs_origin.squeeze(1).squeeze(2)\n",
    "        inputs, labels = inputs_new.to(device), data['label'].to(device)  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = denseNetModel(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % len(trainloader) == len(trainloader) - 1:\n",
    "            average_loss = running_loss / 100\n",
    "            print(f\"Epoch {epoch+1}, Batch {i+1}, Loss: {average_loss:.6f}\")\n",
    "\n",
    "            global_step = epoch * len(trainloader) + i\n",
    "            writer.add_scalar(\"Loss\", average_loss, global_step)\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # 在每个epoch结束后执行验证集评估\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validationloader_Mel:\n",
    "            inputs_origin = data['features']\n",
    "            inputs_new = inputs_origin.squeeze(1).squeeze(2)\n",
    "            inputs, labels = inputs_new.to(device), data['label'].to(device)\n",
    "            outputs = denseNetModel(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * (correct / total)\n",
    "    validations.append(accuracy)\n",
    "    print(f\"Epoch {epoch+1}, Validation Accuracy: {accuracy:.6f}%\")\n",
    "\n",
    "    # 如果当前模型在验证集上表现优于之前的最佳表现，则保存当前模型参数\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        \n",
    "        torch.save(denseNetModel.state_dict(), best_model_path)\n",
    "        print(\"Best model saved with validation accuracy:\", best_accuracy)\n",
    "print(\"After training, the best model saved with validation accuracy:\", best_accuracy)   \n",
    "plt.plot(validations, label = \"Validation Accuracy\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "print(\"mobileNetModel Training finished\")\n",
    "print(\"denseNetModel Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class _Layer1(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super(_Layer1,self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels, growth_rate, kernel_size=3,padding=1, stride=1,bias=False)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(growth_rate)\n",
    "        self.relu1 = torch.nn.ReLU(inplace=True)\n",
    "        self.conv2 = torch.nn.Conv2d(growth_rate,32,kernel_size=3, stride=1, padding=1,bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv2(self.relu1(self.bn1(self.conv1(x))))\n",
    "        out = torch.cat([x,out],1)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class _Layer2(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super(_Layer2,self).__init__()\n",
    "        self.bn1 = torch.nn.BatchNorm2d(in_channels)\n",
    "        self.relu1 = torch.nn.ReLU(inplace=True)\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels, growth_rate, kernel_size=3, stride=1,padding=1,bias=False)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(growth_rate)\n",
    "        self.relu2 = torch.nn.ReLU(inplace=True)\n",
    "        self.conv2 = torch.nn.Conv2d(growth_rate,32,kernel_size=3, stride=1,padding=1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(self.relu1(self.bn1(x)))\n",
    "        out = self.conv2(self.relu2(self.bn2(out)))\n",
    "        out = torch.cat([x,out],1)\n",
    "        return out\n",
    "    \n",
    "class _myNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_myNet,self).__init__()\n",
    "        self.features = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(4,64,kernel_size=3,stride=1,padding=1,bias=False),\n",
    "        torch.nn.BatchNorm2d(64),\n",
    "        torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.layer1 = _Layer1(64,128)\n",
    "        self.layer2 = _Layer2(96,128)\n",
    "        self.layer3 = _Layer2(128,128)\n",
    "        self.norm = nn.BatchNorm2d(160)\n",
    "        self.classifier = nn.Linear(in_features=160, out_features=10, bias=False)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = self.layer3(self.layer2(self.layer1(out)))\n",
    "        return out\n",
    "\n",
    "myModel = _myNet()\n",
    "print(myModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "myModel.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(myModel.parameters(), lr=0.001)\n",
    "\n",
    "best_accuracy = 0.0  # 初始化最佳准确率为0\n",
    "best_model_path = \"./best_mymodel.pth\"  # 模型保存路径\n",
    "validations = []\n",
    "\n",
    "print(\"Number of mini-batches in one epoch:\", len(trainloader_Mel))\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0  \n",
    "    for i, data in enumerate(trainloader_Mel, 0):\n",
    "        inputs_origin = data['features']\n",
    "        inputs_new = inputs_origin.squeeze(1).squeeze(2)\n",
    "        inputs, labels = inputs_new.to(device), data['label'].to(device)  \n",
    "        optimizer.zero_grad()\n",
    "        print(\"Input size:\", inputs_new.size())\n",
    "        \n",
    "        outputs = myModel(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % len(trainloader) == len(trainloader) - 1:\n",
    "            average_loss = running_loss / 100\n",
    "            print(f\"Epoch {epoch+1}, Batch {i+1}, Loss: {average_loss:.6f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # 在每个epoch结束后执行验证集评估\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validationloader_Mel:\n",
    "            inputs_origin = data['features']\n",
    "            inputs_new = inputs_origin.squeeze(1).squeeze(2)\n",
    "            inputs, labels = inputs_new.to(device), data['label'].to(device)\n",
    "            outputs = myModel(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * (correct / total)\n",
    "    validations.append(accuracy)\n",
    "    print(f\"Epoch {epoch+1}, Validation Accuracy: {accuracy:.6f}%\")\n",
    "\n",
    "    # 如果当前模型在验证集上表现优于之前的最佳表现，则保存当前模型参数\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        \n",
    "        torch.save(denseNetModel.state_dict(), best_model_path)\n",
    "        print(\"Best model saved with validation accuracy:\", best_accuracy)\n",
    "print(\"After training, the best model saved with validation accuracy:\", best_accuracy)   \n",
    "plt.plot(validations, label = \"Validation Accuracy\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "print(\"mobileNetModel Training finished\")\n",
    "print(\"denseNetModel Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
